Spark Advanced Wordcount Program using

	1.Resilient Distributed Datsets (RDD)
	2.Dataset
	3.SparkSQLs

Note:- Following Words are treated as same
	HOURS -> hours
	laptop's -> laptop
	buying ->buy
	i.e replaced all ('s,ly,ed,ness,ing) which actually doesn't change the meaning of word

Details to execute code:-

Just provide input path and output directory

Requriements:-
Apache Spark must be installed on machine 
